{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation Using Simple GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter specification for generating text\n",
    "\n",
    "# GPT2 Model Size (either 124M or 355M)\n",
    "gpt2size = '124M'\n",
    "\n",
    "# Location in which to save pretrained GPT2 model\n",
    "gpt2dir = '../gpt2models'\n",
    "\n",
    "# Location from which to load fine-tuned models\n",
    "loaddir = '../trained_models/checkpoint'\n",
    "\n",
    "# Data used to fine-tune model\n",
    "ft_dat = 'wiki_sentence'\n",
    "\n",
    "# Number of steps performed to train model\n",
    "n_steps = 2000\n",
    "\n",
    "# Name of fine-tuned model\n",
    "ft_mod = ft_dat + '_' + gpt2size + '_' + str(n_steps)\n",
    "\n",
    "# Location of raw and clean data\n",
    "ClnDat = '../data_clean/'\n",
    "RawDat = '../data_raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify and download pretrained GPT2 model\n",
    "gpt2.download_gpt2(model_name = gpt2size,\n",
    "                   model_dir = gpt2dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess,\n",
    "               run_name = ft_mod,\n",
    "               checkpoint_dir = loaddir,\n",
    "               model_name = gpt2size,\n",
    "               model_dir = gpt2dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputText = (\n",
    "    \"\"\"\n",
    "    Newton's laws are applied to objects which are idealised as single point masses. \n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpt2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7dd6883a8af9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m gpt2.generate(sess,\n\u001b[0m\u001b[1;32m      2\u001b[0m               \u001b[0mnsamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0mrun_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft_mod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mcheckpoint_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaddir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#               prefix = '<|startoftext|>' + InputText + '|<EndSentence1>|',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gpt2' is not defined"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess,\n",
    "              nsamples = 1,\n",
    "              run_name = ft_mod,\n",
    "              checkpoint_dir = loaddir,\n",
    "#               prefix = '<|startoftext|>' + InputText + '|<EndSentence1>|',\n",
    "#               truncate = '<|endoftext|>',\n",
    "#               include_prefix = False,\n",
    "              temperature = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create single file with sentences matched\n",
    "if os.path.exists(ClnDat+'wiki_sent_pair.csv'):\n",
    "    pass\n",
    "else:\n",
    "    TextDF = pd.read_csv(ClnDat+'wiki_sentence.csv')\n",
    "    TextDF['sent_pair'] = TextDF['normal'] + '\\n |<EndSentence1>| \\n' + TextDF['simple']\n",
    "    TextDF['sent_pair'].to_csv(ClnDat+'wiki_sent_pair.csv', index = False)\n",
    "    TextDF.head()\n",
    "\n",
    "# Initiate tensor flow session for gpt2\n",
    "sess = gpt2.start_tf_sess()\n",
    "\n",
    "# Fine-tune gpt2 model with sentence-matched data\n",
    "gpt2.finetune(sess, \n",
    "              dataset = ClnDat+'wiki_sent_pair.csv', \n",
    "              model_name = gpt2size,\n",
    "              model_dir = gpt2dir,\n",
    "              restore_from = 'fresh',\n",
    "              run_name = 'testrun',\n",
    "              checkpoint_dir = loaddir,\n",
    "              save_every = 500,\n",
    "              use_memory_saving_gradients = False,\n",
    "              steps = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
